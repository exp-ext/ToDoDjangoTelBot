import asyncio
import json
import traceback
from datetime import timedelta

import httpx
import markdown
import tiktoken_async
from asgiref.sync import sync_to_async
from channels.db import database_sync_to_async
from channels.generic.websocket import AsyncWebsocketConsumer
from django.conf import settings
from django.contrib.auth import get_user_model
from django.db.models import Model
from django.utils.timezone import now
from httpx_socks import AsyncProxyTransport
from openai import AsyncOpenAI
from telbot.loader import bot
from telbot.models import GptModels, HistoryAI

ADMIN_ID = settings.TELEGRAM_ADMIN_ID
User = get_user_model()
redis_client = settings.REDIS_CLIENT


class AnswerChatGPT():
    ERROR_TEXT = (
        '–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ü§∑üèº\n'
        '–í–æ–∑–º–æ–∂–Ω–æ –±–æ–ª—å—à–æ–π –Ω–∞–ø–ª—ã–≤ –∑–∞–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —è –Ω–µ —É—Å–ø–µ–≤–∞—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å ü§Ø'
    )
    STORY_WINDOWS_TIME = 30
    MAX_TYPING_TIME = 3

    def __init__(self, channel_layer: AsyncWebsocketConsumer, room_group_name: str, user: Model, message: str, message_count: int) -> None:
        self.channel_layer = channel_layer
        self.room_group_name = room_group_name
        self.message_text = message
        self.user = user
        self.message_count = message_count
        self.current_time = now()
        self.time_start = None
        self.answer_tokens = None
        self.answer_text = AnswerChatGPT.ERROR_TEXT
        self.model = None
        self.prompt = self.init_prompt()
        self.message_tokens = None
        self.set_windows_time()

    async def get_answer_from_ai(self) -> dict:
        """–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞."""

        if await self.check_in_works():
            return None

        await self.get_model_async()

        await self.num_tokens_from_message()

        if self.check_long_query:
            response_message = f'{self.user}, —É –í–∞—Å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –∫–æ—Ä–æ—á–µ.'
            await self.send_chat_message(response_message)
            return None

        try:
            await self.get_prompt()
            await self.httpx_request_to_openai()

        except Exception as err:
            traceback_str = traceback.format_exc()
            text = f'{str(err)[:1024]}\n\n–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:\n{traceback_str[-1024:]}'
            await self.handle_error(text)
        finally:
            if not self.user.is_authenticated and self.message_count == 1:
                welcome_text = (
                    '–î–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥! '
                    '–ü–æ—Å–ª–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ç–µ–±—è –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω —Ä–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞ —Å –ò–ò –ï–≤–∞, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –Ω–∏–∂–µ.'
                )
                await self.send_chat_message(welcome_text)

            await self.send_chat_message(self.answer_text)
            await asyncio.gather(self.create_history_ai(), self.del_mess_in_redis())

    async def request_to_openai(self) -> None:
        """–î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI –∏ –≤—ã–∫–ª—é—á–∞–µ—Ç typing."""
        client = AsyncOpenAI(
            api_key=self.model.token,
            timeout=300,
        )
        completion = await client.chat.completions.create(
            model=self.model.title,
            messages=self.prompt,
            temperature=0.1
        )
        self.answer_text = completion.choices[0].message.content
        self.answer_tokens = completion.usage.completion_tokens
        self.message_tokens = completion.usage.prompt_tokens

    async def httpx_request_to_openai(self) -> None:
        """–î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI –∏ –≤—ã–∫–ª—é—á–∞–µ—Ç typing."""
        transport = AsyncProxyTransport.from_url(settings.SOCKS5)
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.model.token}"
        }
        data = {
            "model": self.model.title,
            "messages": self.prompt,
            "temperature": 0.1
        }
        async with httpx.AsyncClient(transport=transport) as client:
            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=60 * self.MAX_TYPING_TIME,
            )
            completion = json.loads(response.content)
            try:
                self.answer_text = completion.get('choices')[0]['message']['content']
                self.answer_tokens = completion.get('usage')['completion_tokens']
                self.message_tokens = completion.get('usage')['prompt_tokens']
            except Exception as error:
                self.answer_text = '–Ø –æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å!'
                raise error

    async def send_chat_message(self, message):
        await self.channel_layer.group_send(
            self.room_group_name,
            {
                'type': 'chat.message',
                'message': markdown.markdown(message, extensions=['fenced_code']),
                'username': 'Eva',
            }
        )

    async def handle_error(self, err):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫."""
        error_message = f"–û—à–∏–±–∫–∞ –≤ –±–ª–æ–∫–µ –°–∞–π—Ç-ChatGPT:\n{err}"
        bot.send_message(ADMIN_ID, error_message)

    async def num_tokens_from_message(self):
        """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        try:
            encoding = await tiktoken_async.encoding_for_model(self.model.title)
        except KeyError:
            encoding = await tiktoken_async.get_encoding("cl100k_base")
        self.message_tokens = len(encoding.encode(self.message_text)) + 4

    async def create_history_ai(self):
        """–°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –≤ –ë–î."""
        instance = HistoryAI(
            user=self.user if self.user.is_authenticated else None,
            room_group_name=self.room_group_name if self.room_group_name else None,
            question=self.message_text,
            question_tokens=self.message_tokens,
            answer=self.answer_text,
            answer_tokens=self.answer_tokens
        )
        await instance.save()

    async def set_windows_time(self) -> None:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã current_time –∏ time_start."""
        self.time_start = self.current_time - timedelta(minutes=AnswerChatGPT.STORY_WINDOWS_TIME)

    async def get_model_async(self):
        if self.user.is_authenticated:
            self.model = await self._get_user_active_model()
        if not self.model:
            self.model = await self._get_default_model()

    @database_sync_to_async
    def _get_user_active_model(self):
        try:
            return self.user.approved_models.active_model
        except Exception:
            return None

    @staticmethod
    @database_sync_to_async
    def _get_default_model():
        return GptModels.objects.filter(default=True).first()

    @database_sync_to_async
    def get_prompt(self) -> None:
        """Prompt –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI –∏ –º–æ–¥–µ–ª—å user."""
        if self.user.is_authenticated:
            history = (
                self.user
                .history_ai
                .filter(created_at__range=[self.time_start, self.current_time])
                .exclude(answer__isnull=True)
                .values('question', 'question_tokens', 'answer', 'answer_tokens')
            )
            max_tokens = self.message_tokens + 120
            for item in history:
                max_tokens += sum(item.get(key, 0) for key in ('question_tokens', 'answer_tokens') if item.get(key) is not None)
                if max_tokens >= self.model.context_window:
                    break
                self.prompt.extend([
                    {
                        'role': 'user',
                        'content': item['question']
                    },
                    {
                        'role': 'assistant',
                        'content': item['answer']
                    }
                ])
        self.prompt.append({'role': 'user', 'content': self.message_text})

    @sync_to_async
    def check_in_works(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Ç –ª–∏ —É–∂–µ –≤ —Ä–∞–±–æ—Ç–µ —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ Redis."""
        queries = redis_client.lrange(f'gpt_:{self.room_group_name}', 0, -1)
        if self.message_text.encode('utf-8') in queries:
            return True
        redis_client.lpush(f'gpt_:{self.room_group_name}', self.message_text)
        return False

    @sync_to_async
    def del_mess_in_redis(self) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Redis."""
        redis_client.lrem(f'gpt_:{self.room_group_name}', 1, self.message_text.encode('utf-8'))

    @property
    def check_long_query(self) -> bool:
        return self.message_tokens and self.model and self.message_tokens > self.model.max_request_token

    def init_prompt(self):
        return [
            {
                'role': 'system',
                'content':
                    """
                    You are named Eva, an experienced senior software developer with a strong background in team leadership,
                    mentoring all developers, and delivering high-quality software solutions to clients.
                    Your primary language is Russian.
                    """
            },
            {'role': 'user', 'content': self.message_text}
        ]


def convert_markdown(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–≥–∏ Markdown –≤ HTML-—Ç–µ–≥–∏

    ### Args:
    - text (str): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.

    ### Return:
    - (str): –¢–µ–∫—Å—Ç —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
    """

    return markdown.markdown(text, extensions=['fenced_code'])
